/*
ElevenLabs API Documentation

This is the documentation for the ElevenLabs API. You can use this API to use our service programmatically, this is done by using your xi-api-key. <br/> You can view your xi-api-key using the 'Profile' tab on https://elevenlabs.io. Our API is experimental so all endpoints are subject to change.

The version of the OpenAPI document: 1.0


NOTE: This file is auto generated by Konfig (https://konfigthis.com).
*/
import type * as buffer from "buffer"


/**
 * 
 * @export
 * @interface BodySpeechToSpeechV1SpeechToSpeechVoiceIdPost
 */
export interface BodySpeechToSpeechV1SpeechToSpeechVoiceIdPost {
    /**
     * The audio file which holds the content and emotion that will control the generated speech.
     * @type {Uint8Array | File | buffer.File}
     * @memberof BodySpeechToSpeechV1SpeechToSpeechVoiceIdPost
     */
    'audio': Uint8Array | File | buffer.File;
    /**
     * Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for speech to speech, you can check this using the can_do_voice_conversion property.
     * @type {string}
     * @memberof BodySpeechToSpeechV1SpeechToSpeechVoiceIdPost
     */
    'model_id'?: string;
    /**
     * Voice settings overriding stored setttings for the given voice. They are applied only on the given request. Needs to be send as a JSON encoded string.
     * @type {string}
     * @memberof BodySpeechToSpeechV1SpeechToSpeechVoiceIdPost
     */
    'voice_settings'?: string;
}

