/*
ElevenLabs API Documentation

This is the documentation for the ElevenLabs API. You can use this API to use our service programmatically, this is done by using your xi-api-key. <br/> You can view your xi-api-key using the 'Profile' tab on https://elevenlabs.io. Our API is experimental so all endpoints are subject to change.

The version of the OpenAPI document: 1.0


NOTE: This file is auto generated by Konfig (https://konfigthis.com).
*/
import type * as buffer from "buffer"

import { PronunciationDictionaryVersionLocatorDBModel } from './pronunciation-dictionary-version-locator-dbmodel';
import { VoiceSettingsResponseModel } from './voice-settings-response-model';

/**
 * 
 * @export
 * @interface BodyTextToSpeechV1TextToSpeechVoiceIdStreamPost
 */
export interface BodyTextToSpeechV1TextToSpeechVoiceIdStreamPost {
    /**
     * The text that will get converted into speech.
     * @type {string}
     * @memberof BodyTextToSpeechV1TextToSpeechVoiceIdStreamPost
     */
    'text': string;
    /**
     * Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.
     * @type {string}
     * @memberof BodyTextToSpeechV1TextToSpeechVoiceIdStreamPost
     */
    'model_id'?: string;
    /**
     * Voice settings overriding stored setttings for the given voice. They are applied only on the given request.
     * @type {VoiceSettingsResponseModel}
     * @memberof BodyTextToSpeechV1TextToSpeechVoiceIdStreamPost
     */
    'voice_settings'?: VoiceSettingsResponseModel;
    /**
     * A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request
     * @type {Array<PronunciationDictionaryVersionLocatorDBModel>}
     * @memberof BodyTextToSpeechV1TextToSpeechVoiceIdStreamPost
     */
    'pronunciation_dictionary_locators'?: Array<PronunciationDictionaryVersionLocatorDBModel>;
}

